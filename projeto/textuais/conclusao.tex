% CONCLUSÃO--------------------------------------------------------------------

\chapter{CONCLUSÃO}
\label{chap:conclusao}

Este trabalho apresentou o desenvolvimento de um sistema de controle de câmera, do tipo \textit{Pan} e \textit{Tilt}, que utiliza dados relativos ao movimento da cabeça do operador capturados, por um \textit{smartphone}, acoplado ao usuário, através de um óculos do tipo \textit{VR}.\par

Com base nos resultados obtidos, e corrigindo-se questões pertinentes ao envio de imagens de vídeo, um sistema semelhante ao construído, pode ser utilizado para facilitar o manuseio, ou operação, de um robô de inspeção. Sendo assim, um operador pode usar os movimentos de sua cabeça para controlar a câmera de um robô, reduzindo o número de ações vinculada ao controle manual, normalmente necessárias para movimentar o robô, suas ferramentas e a câmera embarcada. \par 
O sistema de imagem \textit{stereo}, aumenta a percepção do local, uma vez que adiciona a sensação de profundidade às imagens, facilita a locomoção, a orientação e, consequentemente, a inspeção de ambientes.

O projeto foi elaborado usando um \textit{Raspberry Pi}, como unidade computacional e de controle dos servo motores da câmera, e um celular \textit{smartphone} \textit{Android}, responsável por coletar e enviar informações referentes a posição espacial do aparelho. O desenvolvimento do projeto proporcionou um melhor entendimento em aspetos relacionados à rede de computadores, sistemas operacionais, interfaces de \textit{hardware}, modulação por largura de pulso, eletrônica e desenvolvimento de sistemas para plataformas móveis.\par

Competências ligadas a construção de \textit{software} puderam ser evoluídas, já que o módulo de controle, embarcado no \textit{Raspberry Pi}, foi construído em linguagem C e o módulo de coleta de dados foi desenvolvido em \textit{Java}, usando a API do sistema operacional \textit{Android}.\par

Todo material desenvolvido está disponível \href{https://github.com/raffsalvetti/ENGG60}{neste endereço}.


\section{Trabalhos Futuros}
\label{sec:trabalhosFuturos}

\begin{itemize}
\item Melhorar o sistema de envio das imagens de vídeo para o celular.
\item Adicionar opção \textit{multicast} para envio de vídeo (vários inspetores podem ver as imagens transmitidas pela câmera mesmo tempo).
\item Adicionar função para captura de foto a partir do vídeo (para análise posterior).
\item Desenvolver um mecanismo automático de calibração do celular (independente da orientação magnética do planeta).
\item Criar um modo de tela cheia para melhor visualização das imagens com o óculos de realidade virtual.
\item Adicionar suporte a conexão \textit{bluetooth} entre um \textit{joysticks} e o celular, permitindo interação com a interface de teste e enviar comandos para o robô.
\item Criar uma API para possibilitar a integração com outras soluções (ex: mostrar dados capturados de sensores embarcados na imagem enviada para o celular).
\item Adicionar suporte aos protocolos de comunicação do ROS (\textit{Robot Operating System}), transformando o MCC e o MCM em nós do ROS. 
\item Adicionar captura de som ambiente \textit{stereo} no módulo de controle dos motores.
\item Transmitir o sinal de som capturado junto com o vídeo para o celular, aumentando a sensação de imersão para o operador.
\item Melhoria do sistema de alimentação para a solução (tornar portátil).
\item Construir uma placa para evitar o mau contato entre componentes eletrônicos no circuito de acionamento dos motores (construção de uma \textit{Raspberry Pi hat}).
\end{itemize}
